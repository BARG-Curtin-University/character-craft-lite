#!/usr/bin/env python3
import os
import sys
import json
import argparse
from anthropic import Anthropic

def ask(question):
    """
    Prompt the user with a question and return their response.
    
    Args:
        question (str): The question to ask the user
    
    Returns:
        str: The user's response
    """
    return input(question)


def generate_statistical_report(instances, word_mappings, code):
    """
    Generate a statistical analysis report of American/British spelling differences.
    
    Args:
        instances (list): List of spelling instances found
        word_mappings (dict): Dictionary of American to British word mappings
        code (str): Original source code
        
    Returns:
        dict: Statistical information
    """
    # Prepare the stats dictionary
    stats = {
        "frequency": {},        # Word frequency analysis
        "file_stats": {},       # File statistics
        "categories": {}        # Word categorization
    }
    
    # 1. Frequency Analysis
    for instance in instances:
        american = instance.get("american", "")
        if not american:
            continue
            
        if american in stats["frequency"]:
            stats["frequency"][american] += 1
        else:
            stats["frequency"][american] = 1
    
    # Sort frequency by count (descending)
    stats["frequency"] = dict(sorted(
        stats["frequency"].items(), 
        key=lambda item: item[1], 
        reverse=True
    ))
    
    # 2. File Statistics
    total_lines = len(code.splitlines())
    affected_lines = len(set(instance.get("line", 0) for instance in instances))
    
    stats["file_stats"] = {
        "total_lines": total_lines,
        "affected_lines": affected_lines,
        "percentage_affected": round((affected_lines / total_lines) * 100, 2) if total_lines > 0 else 0,
        "total_instances": len(instances),
        "unique_words": len(word_mappings)
    }
    
    # Calculate distribution by file regions
    if total_lines > 0:
        top_third = 0
        middle_third = 0
        bottom_third = 0
        
        third_size = total_lines // 3
        
        for instance in instances:
            line = instance.get("line", 0)
            if line <= third_size:
                top_third += 1
            elif line <= third_size * 2:
                middle_third += 1
            else:
                bottom_third += 1
        
        stats["file_stats"]["distribution"] = {
            "top_third": top_third,
            "middle_third": middle_third,
            "bottom_third": bottom_third
        }
    
    # 3. Word Categorization
    categories = {
        "ize_ise": [],    # e.g., organize/organise
        "or_our": [],     # e.g., color/colour
        "er_re": [],      # e.g., center/centre
        "ense_ence": [],  # e.g., defense/defence
        "og_ogue": [],    # e.g., dialog/dialogue
        "am_amme": [],    # e.g., program/programme
        "l_ll": [],       # e.g., fulfil/fulfill
        "other": []       # Other patterns
    }
    
    for american, british in word_mappings.items():
        # Check for common patterns
        if american.endswith('ize') and british.endswith('ise'):
            categories["ize_ise"].append((american, british))
        elif 'or' in american and 'our' in british:
            categories["or_our"].append((american, british))
        elif american.endswith('er') and british.endswith('re'):
            categories["er_re"].append((american, british))
        elif american.endswith('ense') and british.endswith('ence'):
            categories["ense_ence"].append((american, british))
        elif american.endswith('og') and british.endswith('ogue'):
            categories["og_ogue"].append((american, british))
        elif american.endswith('am') and british.endswith('amme'):
            categories["am_amme"].append((american, british))
        elif american.endswith('l') and british.endswith('ll'):
            categories["l_ll"].append((american, british))
        else:
            categories["other"].append((american, british))
    
    # Only include non-empty categories
    stats["categories"] = {k: v for k, v in categories.items() if v}
    
    # Add category counts
    stats["category_counts"] = {k: len(v) for k, v in stats["categories"].items()}
    
    return stats


def display_statistical_report(stats):
    """
    Display the statistical analysis report.
    
    Args:
        stats (dict): Statistical information generated by generate_statistical_report
    """
    print("\nüìä STATISTICAL ANALYSIS REPORT üìä")
    
    # 1. File Statistics
    print("\nüìÅ FILE STATISTICS:")
    file_stats = stats["file_stats"]
    print(f"   Total lines in file: {file_stats['total_lines']}")
    print(f"   Lines with spelling changes: {file_stats['affected_lines']} ({file_stats['percentage_affected']}%)")
    print(f"   Total instances found: {file_stats['total_instances']}")
    print(f"   Unique American words: {file_stats['unique_words']}")
    
    # Distribution by file region
    if "distribution" in file_stats:
        dist = file_stats["distribution"]
        print("\n   Distribution by file region:")
        print(f"     Top third: {dist['top_third']} instances")
        print(f"     Middle third: {dist['middle_third']} instances")
        print(f"     Bottom third: {dist['bottom_third']} instances")
    
    # 2. Word Frequency Analysis
    print("\nüìâ WORD FREQUENCY ANALYSIS:")
    if stats["frequency"]:
        print("   Most common American spellings:")
        for i, (word, count) in enumerate(list(stats["frequency"].items())[:10], 1):
            print(f"   {i}. '{word}': {count} occurrences")
        
        if len(stats["frequency"]) > 10:
            print(f"   ... and {len(stats['frequency']) - 10} more.")
    else:
        print("   No frequency data available.")
    
    # 3. Word Categorization
    print("\nüî§ SPELLING PATTERN ANALYSIS:")
    categories = stats["category_counts"]
    
    patterns = {
        "ize_ise": "-ize ‚Üí -ise (e.g., organize/organise)",
        "or_our": "-or ‚Üí -our (e.g., color/colour)",
        "er_re": "-er ‚Üí -re (e.g., center/centre)",
        "ense_ence": "-ense ‚Üí -ence (e.g., defense/defence)",
        "og_ogue": "-og ‚Üí -ogue (e.g., dialog/dialogue)",
        "am_amme": "-am ‚Üí -amme (e.g., program/programme)",
        "l_ll": "-l ‚Üí -ll (e.g., fulfill/fulfil)",
        "other": "Other patterns"
    }
    
    if categories:
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            pattern_desc = patterns.get(category, category)
            print(f"   {pattern_desc}: {count} words")
            
            # Show examples of each category
            if stats["categories"].get(category):
                examples = stats["categories"][category][:3]  # Show up to 3 examples
                examples_str = ", ".join([f"{am}/{br}" for am, br in examples])
                if examples:
                    print(f"     Examples: {examples_str}")
                if len(stats["categories"][category]) > 3:
                    print(f"     ... and {len(stats['categories'][category]) - 3} more.")
    else:
        print("   No categorization data available.")
    
    print("\nüìã RECOMMENDATION:")
    # Make a recommendation based on the patterns
    if categories:
        most_common = max(categories.items(), key=lambda x: x[1])
        most_common_pattern = patterns.get(most_common[0], most_common[0])
        print(f"   Most common spelling pattern: {most_common_pattern}")
        print(f"   Focus on standardizing this pattern for greatest impact.")
    else:
        print("   No specific recommendations available.")
        
    print("\n")  # Add extra line for spacing


def apply_changes(file_path, output_path, original_code, instances, args):
    """
    Apply spelling changes to the code and save to a new file.
    
    Args:
        file_path (str): Original file path
        output_path (str or None): Output file path, if None a default path is created
        original_code (str): Original code content
        instances (list): Instances of spelling to change
        args (Namespace): Command line arguments
    """
    if not args.quiet:
        print("\nüîÑ Preparing to apply changes...")
    
    # If no output path provided, create one with "-uk" suffix
    if not output_path:
        file_name, file_ext = os.path.splitext(file_path)
        output_path = f"{file_name}-uk{file_ext}"
        if not args.quiet:
            print(f"üìÑ No output path specified, using: {output_path}")
    elif not args.quiet:
        print(f"üìÑ Output will be written to: {output_path}")
    
    # Confirm overwrite if output file exists
    if os.path.exists(output_path) and output_path != file_path:
        confirm = ask(f"‚ö†Ô∏è File {output_path} already exists. Overwrite? (y/n): ").lower()
        if confirm not in ['y', 'yes']:
            print("‚ùå Operation cancelled.")
            return
    
    # Sort instances by line number in descending order to avoid offset issues
    # when making multiple replacements
    sorted_instances = sorted(
        instances, 
        key=lambda x: x.get("line", 0),
        reverse=True
    )
    
    # Copy the original code
    modified_code = original_code
    
    # Process each change - this is a simplified approach and might not work for all cases
    # A more robust solution would involve parsing the JavaScript AST
    if not args.quiet:
        print("\nüîÑ Applying changes:")
    changes_applied = 0
    
    for instance in sorted_instances:
        american = instance.get("american", "")
        british = instance.get("british", "")
        context = instance.get("context", "")
        
        if american and british and context:
            # Handle full context replacement
            if context in modified_code:
                new_context = context.replace(american, british)
                old_code = modified_code
                modified_code = modified_code.replace(context, new_context)
                
                # Verify the change was made
                if old_code != modified_code:
                    changes_applied += 1
                    if not args.quiet and args.report == 'detailed':
                        print(f"‚úì Replaced: {american} ‚Üí {british}")
                elif not args.quiet and args.report == 'detailed':
                    print(f"‚ö†Ô∏è No change for: {american} ‚Üí {british}")
            elif not args.quiet and args.report == 'detailed':
                print(f"‚ö†Ô∏è Could not find context: {context}")
        elif not args.quiet and args.report == 'detailed':
            print(f"‚ö†Ô∏è Incomplete data for spelling change")
    
    # Write the modified code to the output file
    try:
        with open(output_path, 'w', encoding='utf-8') as file:
            file.write(modified_code)
            
        print(f"\n‚úÖ Applied {changes_applied} spelling changes to: {output_path}")
    except Exception as e:
        print(f"‚ùå Error writing file: {str(e)}")
        sys.exit(1)


def main():
    """
    Main function to standardize American spellings to British/Australian in JavaScript files.
    """
    # Set up command line argument parsing
    parser = argparse.ArgumentParser(description='Standardize American to British/Australian spelling in JavaScript code')
    parser.add_argument('file_path', help='Path to the JavaScript file')
    parser.add_argument('--apply', '-a', action='store_true', 
                       help='Apply the suggested changes automatically (use with caution)')
    parser.add_argument('--output', '-o', help='Output file path (defaults to creating a new file with "-uk" suffix)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Show more detailed output during processing')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='Minimal output, only show errors and final summary')
    parser.add_argument('--report', '-r', 
                        choices=['none', 'summary', 'detailed', 'stats', 'full'],
                        default='summary',
                        help='''Control reporting level: 
                              none=no report, 
                              summary=word count only, 
                              detailed=full listing, 
                              stats=statistical analysis,
                              full=all reports combined 
                              (default: summary)''')
    args = parser.parse_args()
    
    file_path = args.file_path
    
    # Check if file exists
    if not os.path.exists(file_path):
        print('‚ùå Please provide a valid JavaScript file path.')
        sys.exit(1)
    
    # Read the JavaScript code
    with open(file_path, 'r', encoding='utf-8') as file:
        code = file.read()
    
    # Create the prompt for Claude
    prompt = f"""
Analyze this JavaScript code and identify any instances of American English spelling in:
1. Function names
2. Variable names
3. Object property names
4. Comments (pay special attention to all comment types: //, /*...*/, JSDoc comments)
5. String literals

For each instance, suggest the equivalent British/Australian English spelling.
Format your response as a structured JSON object with the following format:

```json
{{
  "american_to_british": {{
    "color": "colour",
    "initialize": "initialise",
    // other word pairs
  }},
  "instances": [
    {{
      "type": "function_name",
      "line": 42,
      "american": "initializeColor",
      "british": "initialiseColour",
      "context": "function initializeColor() {{" 
    }},
    // other instances
  ]
}}
```

The "american_to_british" section should contain direct word mappings,
while the "instances" array should contain specific occurrences in the code
with enough context to locate them.

Only include true spelling differences (color/colour, 
organize/organise), not differences in terminology or phrasing.

Pay particular attention to comments. Even if they appear within larger text blocks,
each comment line or paragraph should be analyzed for American spellings.
Be thorough with comments as they're important for documentation.

IMPORTANT EXCEPTIONS - DO NOT change any of the following:
1. Standard JavaScript built-in functions and methods like:
   - normalize/normalizeSync (String methods)
   - indexOf, lastIndexOf (String/Array methods)
   - toLocaleString, toLocaleDateString, toLocaleTimeString
   - encodeURIComponent, decodeURIComponent
   - Intl.Collator, Intl.NumberFormat, Intl.DateTimeFormat
   - Any standard DOM methods like querySelector

2. External library methods and functions:
   - Don't modify anything imported from modules or libraries
   - Don't change method names on objects created from libraries

3. Web API related terms:
   - localStorage, sessionStorage
   - ServiceWorker, SharedWorker
   - customElements, shadowRoot
   - navigator, authorization, credentials

4. Standardized naming conventions:
   - Lifecycle methods like componentDidMount in React
   - Event handlers like onMouseOver
   - Any camelCase naming pattern where "color" appears as "Color"

Only suggest changes when you're very confident they won't break the code's functionality.

Here is the code:
```js
{code}
```

Return only the JSON output, nothing else.
"""
    
    # Initialize the Anthropic client (Claude)
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        print("‚ùå ANTHROPIC_API_KEY environment variable not set.")
        print("Please set your API key with: export ANTHROPIC_API_KEY=your_api_key_here")
        sys.exit(1)
        
    client = Anthropic(api_key=api_key)
    
    # Send the request to Claude
    try:
        if not args.quiet:
            print('üí¨ Analyzing code for American English spellings...')
        
        message = client.messages.create(
            model="claude-3-7-sonnet-20250219",
            max_tokens=4000,
            temperature=0.2,
            system="You are an expert in British/Australian English spelling and JavaScript conventions. Your task is to identify American English spellings in code and suggest British/Australian alternatives.",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        # Extract the response from Claude
        response_text = message.content[0].text
        
        # Try to parse the JSON from the response
        # First, strip any markdown code block formatting if present
        cleaned_response = response_text
        
        # Handle case where the entire response is a markdown code block
        if cleaned_response.startswith("```json") or cleaned_response.startswith("```"):
            # Find the first line break to skip the opening markdown
            first_line_break = cleaned_response.find('\n')
            if first_line_break != -1:
                # Find the last closing markdown
                last_backticks = cleaned_response.rfind("```")
                if last_backticks != -1:
                    # Extract only the content between the markers
                    cleaned_response = cleaned_response[first_line_break+1:last_backticks].strip()
        
        # Parse the JSON
        try:
            spelling_data = json.loads(cleaned_response)
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parsing Claude's response as JSON: {e}")
            print("Raw response:")
            print(response_text)
            sys.exit(1)
        
        # Display the findings based on reporting level
        word_mappings = spelling_data.get("american_to_british", {})
        instances = spelling_data.get("instances", [])
        
        if not instances:
            if not args.quiet:
                print("‚úÖ No American English spellings found in the code.")
            return
        
        # Report findings based on selected report level
        if not args.quiet:
            # Generate stats for stats or full report modes
            if args.report in ['stats', 'full']:
                stats = generate_statistical_report(instances, word_mappings, code)
            
            # Display based on report type
            if args.report == 'full':
                # Display everything
                print(f"\nüîç Found {len(instances)} instances of American English spelling:")
                
                # Detailed listing
                for i, instance in enumerate(instances, 1):
                    instance_type = instance.get("type", "unknown")
                    line = instance.get("line", "unknown")
                    american = instance.get("american", "")
                    british = instance.get("british", "")
                    context = instance.get("context", "")
                    
                    print(f"\n{i}. {instance_type.upper()} (line {line}):")
                    print(f"   American: {american}")
                    print(f"   British:  {british}")
                    print(f"   Context:  {context}")
                
                print("\nüìù Word mappings (American ‚Üí British):")
                for american, british in word_mappings.items():
                    print(f"   {american} ‚Üí {british}")
                
                # Statistical report
                display_statistical_report(stats)
                
            elif args.report == 'detailed':
                print(f"\nüîç Found {len(instances)} instances of American English spelling:")
                
                for i, instance in enumerate(instances, 1):
                    instance_type = instance.get("type", "unknown")
                    line = instance.get("line", "unknown")
                    american = instance.get("american", "")
                    british = instance.get("british", "")
                    context = instance.get("context", "")
                    
                    print(f"\n{i}. {instance_type.upper()} (line {line}):")
                    print(f"   American: {american}")
                    print(f"   British:  {british}")
                    print(f"   Context:  {context}")
                
                print("\nüìù Word mappings (American ‚Üí British):")
                for american, british in word_mappings.items():
                    print(f"   {american} ‚Üí {british}")
                    
            elif args.report == 'stats':
                # Just display the statistical report
                display_statistical_report(stats)
                
            elif args.report == 'summary':
                # Group by type and show counts
                print(f"\nüîç Found {len(instances)} instances of American English spelling:")
                
                types = {}
                for instance in instances:
                    instance_type = instance.get("type", "unknown")
                    types[instance_type] = types.get(instance_type, 0) + 1
                
                for type_name, count in types.items():
                    print(f"   {type_name}: {count} instances")
                    
                print(f"\n   Total words to change: {len(word_mappings)}")
        
        # Handle applying changes
        if len(instances) > 0:
            if args.apply:
                # Auto-apply with --apply flag
                output_path = args.output  # This might be None, which is handled in apply_changes
                apply_changes(file_path, output_path, code, instances, args)
            else:
                # Interactive mode
                should_apply = ask("\nüìä Would you like to apply these changes? (y/n): ").lower()
                if should_apply in ['y', 'yes']:
                    output_path = args.output
                    if not output_path:
                        output_path = ask(
                            "üìÅ Enter output file path (or press Enter to create a new file with '-uk' suffix): "
                        )
                    apply_changes(file_path, output_path, code, instances, args)
                else:
                    print("‚ùå No changes applied.")
        else:
            print("‚ùå No changes to apply.")
    
    except Exception as e:
        print(f"‚ùå Error communicating with Claude API: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()